{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f75942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos las librerías a utilizar\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858acaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las columnas que no vamos a tomar en cuenta\n",
    "cols_remove = ['mantenimiento', 'fecha']\n",
    "# Definimos las columnas que van a ser los datos de entrada (X)\n",
    "cols_X = ['vel_motor', 'voltaje', 'mensaje_volt', 'horas_comp_trabajadas',\n",
    " 'temp_planta', 'Radiation_mrh', 'problemas_rechazo'] #'Lamps', 'Lead Curtains',\n",
    "# Definimos las variables que vamos a predecir (y)\n",
    "cols_y = ['rep_filtro_aire', 'rep_tubo', 'rep_tarjeta_detector', 'rep_IOB',\n",
    " 'rep_otras_tarj', 'rep_motor', 'rep_software', 'rep_PILZ', 'rep_shutter',\n",
    " 'rep_cables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c47cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos el archivo de un equipo #Serie E162533\n",
    "init_df = pd.read_excel(\"equipo-E162533_v2.xlsx\")\n",
    "init_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642bccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos los dataframes para 'X' e 'y'\n",
    "df_X = init_df.copy()[cols_X]\n",
    "df_y = init_df.copy()[cols_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c104e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizamos los valores de 'X' que vamos a utilizar\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = mm_scaler.fit_transform(df_X)\n",
    "std_df_X = pd.DataFrame(mm_scaler.transform(df_X), columns = cols_X)\n",
    "std_df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003b9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizamos los valores de 'y'\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = mm_scaler.fit_transform(df_y)\n",
    "std_df_y = pd.DataFrame(mm_scaler.transform(df_y), columns = cols_y)\n",
    "std_df_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901f65de",
   "metadata": {},
   "source": [
    "- https://arxiv.org/pdf/1407.7502.pdf\n",
    "- https://towardsdatascience.com/understanding-random-forest-58381e0602d2\n",
    "- https://www.cienciadedatos.net/documentos/py08_random_forest_python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3452b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_modelo_rf(df_X, df_Y, test_size=0.2, n_estimators = 100, \n",
    "                      criterion='gini',  min_samples_leaf=1, \n",
    "                      min_samples_split=2, n_jobs=1, logistic_model=False):\n",
    "    '''\n",
    "    '''\n",
    "    # Creamos un objeto donde vamos a ir guardando los resultados\n",
    "    results = {\n",
    "        'y': df_Y.name\n",
    "    }\n",
    "    \n",
    "    # dividimos en sets de entrenamiento y de prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=test_size)\n",
    "    \n",
    "    if (logistic_model):\n",
    "        # creamos un Regresor Logístico\n",
    "        clf = RandomForestRegressor(n_estimators=n_estimators,criterion=criterion,\n",
    "            max_depth=None,max_samples=0.7,oob_score=False,\n",
    "            n_jobs=-1,random_state=6)\n",
    "    else:\n",
    "        # creamos un Clasificador Gaussiano\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    \n",
    "    # Entrenamos el modelo utilizando los sets de entrenamiento\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    # Si save_model=True entonces guardamos el modelo como pickle\n",
    "    if(logistic_model):\n",
    "        filename = f'model_{df_Y.name}.sav'\n",
    "        pickle.dump(clf, open(filename, 'wb'))\n",
    "        results['model'] = filename\n",
    "    \n",
    "    # Utilizamos el modelo para crear una predicción\n",
    "    y_pred=clf.predict(X_test)\n",
    "    \n",
    "    if(logistic_model):\n",
    "        # obtenemos el error medio cuadrático\n",
    "        results['mse'] = metrics.mean_squared_error(y_true=y_test,y_pred=y_pred)\n",
    "    else:\n",
    "        # obtenemos la precisión  y la guardamos en los resultados\n",
    "        results['accuracy'] = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # creamos el clasificador para obtener las variables relevantes para esta 'y'\n",
    "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion=criterion,\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, \n",
    "            min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=n_jobs,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "    feature_imp = pd.Series(clf.feature_importances_,index=df_X.columns).sort_values(ascending=False)\n",
    "    \n",
    "    # Guardamos las primeras 5 columnas, que son las más representativas\n",
    "    results['columnas'] = feature_imp.head().to_dict()\n",
    "    \n",
    "    # Regresamos el resultado del modelo\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada 'y' vamos a obtener cuales son las 'X' más representativas\n",
    "results = []\n",
    "\n",
    "for y in cols_y:\n",
    "    df_aux_Y = std_df_y.copy()[y]\n",
    "    print(df_aux_Y.name)\n",
    "    results.append(calcula_modelo_rf(std_df_X,df_aux_Y,0.2,100,'gini',1,2,1,False))\n",
    "\n",
    "# Imprimimos los resultados\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6293daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ya con las variables 'X' más importantes para cada 'y' ahora si entrenamos un modelo\n",
    "# que de una sola predicción y que sea interpretable\n",
    "final_results = []\n",
    "\n",
    "for obj in results:\n",
    "    # obtenemos los dataframes auxiliares con los datos de los resultados anteriores\n",
    "    df_aux_Y = std_df_y.copy()[obj['y']]\n",
    "    df_aux_X = std_df_X.copy()[obj['columnas'].keys()]\n",
    "    print(df_aux_Y.name)\n",
    "    print(df_aux_X.columns)\n",
    "    # Guardamos los resultados para revisar el MSE\n",
    "    final_results.append(calcula_modelo_rf(df_aux_X,df_aux_Y,0.2,100,'squared_error',1,2,1,True))\n",
    "    \n",
    "# Imprimimos los resultados\n",
    "#final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardamos los resultados en un JSON\n",
    "with open('outputfile.json', 'w', encoding='utf-8') as fout:\n",
    "    json.dump(final_results, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074ab3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leemos los resultados del JSON\n",
    "f = open('outputfile.json')\n",
    "data = json.load(f)\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792aedae",
   "metadata": {},
   "source": [
    "### Prueba de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b65f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividimos en sets de entrenamiento y de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(std_df_X, std_df_y, test_size=0.2)\n",
    "\n",
    "# Para cargar el modelo guardado:\n",
    "for y in data:\n",
    "    \n",
    "    # Obtenemos los dataframes con las columnas que nos interesan\n",
    "    df_test_X = X_test.copy()[y['columnas'].keys()]\n",
    "    df_test_y = y_test.copy()[y['y']]\n",
    "    \n",
    "    # cargamos el modelo guardado\n",
    "    filename = y['model']\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    \n",
    "    # checamos el orden de los features para ponerlos en el mismo orden\n",
    "    cols_when_model_builds = model.feature_names_in_\n",
    "    #print(f'outputs: {model.n_outputs_}')\n",
    "    \n",
    "    # Creamos el dataframe con los features en el orden que deben de ir\n",
    "    df_test_X = pd.DataFrame(df_test_X,columns=cols_when_model_builds)\n",
    "    \n",
    "    # para hacer la predicción pasamos el dataframe con los valores de prueba recien generados\n",
    "    y_pred = model.predict(df_test_X)\n",
    "    \n",
    "    # la predicción del RandomForest es el promedio de los outputs\n",
    "    y_pred_int = np.rint(np.average(y_pred, axis=1))\n",
    "    \n",
    "    # comparamos el error cuadrado medio\n",
    "    mse = metrics.mean_squared_error(df_test_y, y_pred_int)\n",
    "    print(f'Model: {filename} - MSE: {mse}') #\\n Pred_int: \\n {y_pred_int} \\n vs real:\\n {df_test_y} - MSE: {mse}')# \\n predicción:\\n {y_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f6e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce385ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
